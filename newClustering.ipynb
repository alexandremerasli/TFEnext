{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful packages\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Work with Python array and graphs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Cluster tendency\n",
    "from pyclustertend import hopkins\n",
    "\n",
    "# Mapping\n",
    "from sklearn.metrics import pairwise_distances, accuracy_score\n",
    "from coclust.evaluation.external import accuracy\n",
    "from skbio.stats.ordination import pcoa\n",
    "from multiview.mvmds import mvmds\n",
    "\n",
    "# Clustering algorithm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "#from KMedoidsPaper import KMedoids\n",
    "\n",
    "# Clustering performance evaluation\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn==0.22.1\n",
      "numpy==1.17.0\n",
      "matplotlib==3.2.1\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "import types\n",
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            # Split ensures you get root package, \n",
    "            # not just imported function\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        # Some packages are weird and have different\n",
    "        # imported names vs. system/pip names. Unfortunately,\n",
    "        # there is no systematic way to get pip names from\n",
    "        # a package's imported name. You'll have to add\n",
    "        # exceptions to this list manually!\n",
    "        poorly_named_packages = {\n",
    "            \"PIL\": \"Pillow\",\n",
    "            \"sklearn\": \"scikit-learn\"\n",
    "        }\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "# The only way I found to get the version of the root package\n",
    "# from only the name of the package is to cross-check the names \n",
    "# of installed packages vs. imported packages\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "\n",
    "for r in requirements:\n",
    "    print(\"{}=={}\".format(*r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISC_EDA = np.genfromtxt(os.path.join('school_EDA12.csv'),delimiter=',')\n",
    "ISC_EDA = np.array(ISC_EDA,dtype='float') # Convert into array\n",
    "\n",
    "ISC_IBI = np.genfromtxt(os.path.join('school_IBI.csv'),delimiter=',')\n",
    "ISC_IBI = np.array(ISC_IBI,dtype='float') # Convert into array\n",
    "\n",
    "#ISC_IBI = ISC_IBI[0:10,0:10]\n",
    "ISC_IBI = ISC_EDA\n",
    "'''\n",
    "print(ISC_EDA.shape)\n",
    "print(ISC_IBI.shape)\n",
    "print(ISC_EDA[:4,:4])\n",
    "print(ISC_IBI[:4,:4])\n",
    "'''\n",
    "\n",
    "'''\n",
    "nPeriod = 2\n",
    "ISC_EDA = np.reshape(ISC_EDA.T,(ISC_EDA.shape[0]*nPeriod,ISC_EDA.shape[0]*nPeriod))\n",
    "print(ISC_EDA[:4,:4])\n",
    "\n",
    "order = np.concatenate((np.arange(0,ISC_EDA.shape[0],2),np.arange(1,ISC_EDA.shape[0],2)))\n",
    "print(order)\n",
    "#ISC_EDA = ISC_EDA[:,order]\n",
    "print(ISC_EDA[:4,:4])\n",
    "\n",
    "import csv\n",
    "\n",
    "print(ISC_EDA[:4,:4])\n",
    "with open(os.path.join('test.csv'), 'w') as File:\n",
    "    writer = csv.writer(File,delimiter =',')\n",
    "    writer.writerows(ISC_EDA)\n",
    "\n",
    "(1,1),(1,2),(2,1),(2,2)\n",
    "(1,1),(1,2),(1,3),(2,1),(2,2),(2,3)\n",
    "'''\n",
    "\n",
    "nPeriod = 3\n",
    "\n",
    "ISC_EDA_sh = np.zeros((ISC_EDA.shape[0]*nPeriod,ISC_EDA.shape[0]*nPeriod))\n",
    "\n",
    "nParticipants = ISC_EDA.shape[0]\n",
    "for period1 in range(nPeriod):\n",
    "    for period2 in range(nPeriod):\n",
    "        if (period1 == period2):\n",
    "            subISC_EDA = np.nan_to_num(ISC_EDA[:,nParticipants*(nPeriod*period1+period2):nParticipants*(nPeriod*period1+period2+1)])\n",
    "            subISC_EDA = (subISC_EDA+subISC_EDA.T)/2\n",
    "        else:\n",
    "            subISC_EDA = ISC_EDA[:,nParticipants*(nPeriod*period1+period2):nParticipants*(nPeriod*period1+period2+1)]\n",
    "        ISC_EDA_sh[nParticipants*period1:nParticipants*(period1+1),nParticipants*period2:nParticipants*(period2+1)] = subISC_EDA\n",
    "        \n",
    "ISC_EDA_sh = np.nan_to_num(ISC_EDA_sh)\n",
    "ISC_EDA_sh = (ISC_EDA_sh+ISC_EDA_sh.T)/2\n",
    "\n",
    "with open(os.path.join('test.csv'), 'w') as File:\n",
    "    writer = csv.writer(File,delimiter =',')\n",
    "    writer.writerows(ISC_EDA_sh)        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(12, 0), dtype=float64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ISC_EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert 2D to 4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnPeriod = 7\\nISC_EDA = np.zeros((ISC_EDA_2D.shape[0],int(ISC_EDA_2D.shape[1]/(nPeriod**2)),nPeriod,nPeriod))\\nfor i in range(nPeriod):\\n    ISC_EDA[:,:,i] = ISC_EDA_2D[:,80*i:80*(i+1)]\\n    \\nprint(ISC_EDA.shape)\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "nPeriod = 7\n",
    "ISC_EDA = np.zeros((ISC_EDA_2D.shape[0],int(ISC_EDA_2D.shape[1]/(nPeriod**2)),nPeriod,nPeriod))\n",
    "for i in range(nPeriod):\n",
    "    ISC_EDA[:,:,i] = ISC_EDA_2D[:,80*i:80*(i+1)]\n",
    "    \n",
    "print(ISC_EDA.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 576 into shape (48,48)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-bddbff9676d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnPeriod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mISC_EDA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mISC_EDA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mISC_EDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnPeriod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mISC_EDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnPeriod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    299\u001b[0m            [5, 6]])\n\u001b[1;32m    300\u001b[0m     \"\"\"\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 576 into shape (48,48)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 12, 2, 2)\n",
      "(12, 12, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "nPeriod = 2\n",
    "ISC_EDA = np.reshape(ISC_EDA,(ISC_EDA.shape[0],int(ISC_EDA.shape[1]/(nPeriod**2)),nPeriod,nPeriod))\n",
    "ISC_IBI = np.reshape(ISC_IBI,(ISC_IBI.shape[0],int(ISC_IBI.shape[1]/(nPeriod**2)),nPeriod,nPeriod))\n",
    "\n",
    "print(ISC_EDA.shape)\n",
    "print(ISC_IBI.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1.          0.0012741 ]\n",
      "   [-0.00522462  0.10596289]]\n",
      "\n",
      "  [[-0.06624189  0.1331691 ]\n",
      "   [ 0.03966898  0.07988962]]\n",
      "\n",
      "  [[-0.05636186  0.00549036]\n",
      "   [-0.00102018 -0.0311848 ]]\n",
      "\n",
      "  [[        nan         nan]\n",
      "   [        nan         nan]]]\n",
      "\n",
      "\n",
      " [[[        nan  1.        ]\n",
      "   [ 0.08565648  0.05887569]]\n",
      "\n",
      "  [[ 0.0825501  -0.01458217]\n",
      "   [ 0.0417097   0.04315329]]\n",
      "\n",
      "  [[ 0.02448747  0.04746752]\n",
      "   [-0.044703    0.05660416]]\n",
      "\n",
      "  [[        nan         nan]\n",
      "   [        nan         nan]]]\n",
      "\n",
      "\n",
      " [[[        nan         nan]\n",
      "   [ 1.          0.02887525]]\n",
      "\n",
      "  [[ 0.06853396  0.03190265]\n",
      "   [ 0.05424124  0.08169548]]\n",
      "\n",
      "  [[ 0.09481458  0.04653178]\n",
      "   [ 0.00850191  0.07571949]]\n",
      "\n",
      "  [[        nan         nan]\n",
      "   [        nan         nan]]]\n",
      "\n",
      "\n",
      " [[[        nan         nan]\n",
      "   [        nan  1.        ]]\n",
      "\n",
      "  [[ 0.00386656  0.0773269 ]\n",
      "   [ 0.05350186  0.03969771]]\n",
      "\n",
      "  [[ 0.03881674  0.04403298]\n",
      "   [ 0.04751731  0.04638156]]\n",
      "\n",
      "  [[        nan         nan]\n",
      "   [        nan         nan]]]]\n"
     ]
    }
   ],
   "source": [
    "print(ISC_EDA[:4,:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing specific to these matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.03312094 -0.02818093  0.        ]\n",
      " [-0.03312094  0.0825501   0.04651072  0.00193328]\n",
      " [-0.02818093  0.04651072  0.09481458  0.01940837]\n",
      " [ 0.          0.00193328  0.01940837  0.        ]]\n",
      "[[ 1.         -0.03312094 -0.02818093  0.        ]\n",
      " [-0.03312094  0.0825501   0.04651072  0.00193328]\n",
      " [-0.02818093  0.04651072  0.09481458  0.01940837]\n",
      " [ 0.          0.00193328  0.01940837  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Symetrical matrices\n",
    "ISC_EDA = np.nan_to_num(ISC_EDA)\n",
    "ISC_IBI = np.nan_to_num(ISC_IBI)\n",
    "ISC_EDA = (ISC_EDA+np.swapaxes(ISC_EDA,0,1))/2\n",
    "ISC_IBI = (ISC_IBI+np.swapaxes(ISC_IBI,0,1))/2\n",
    "\n",
    "print(ISC_EDA[:4,:4,0,0])\n",
    "print(ISC_IBI[:4,:4,0,0])\n",
    "\n",
    "#ISC_EDA = ISC_EDA[:,:,0,0]\n",
    "#ISC_IBI = ISC_IBI[:,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "ISC_EDA = np.swapaxes(ISC_EDA,1,2)\n",
    "ISC_EDA = np.flip(ISC_EDA,3)\n",
    "print(ISC_EDA.shape[0])\n",
    "ISC_EDA = np.reshape(ISC_EDA,((ISC_EDA.shape[0]*ISC_EDA.shape[1],ISC_EDA.shape[0]*ISC_EDA.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.                 nan         nan         nan]\n",
      " [-0.00522462  1.                 nan         nan]\n",
      " [-0.06624189  0.06853396  1.                 nan]\n",
      " [ 0.03966898  0.05424124  0.05794409  1.        ]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.0012741  -0.00522462  0.10596289]\n",
      " [ 0.07988962 -0.05636186  0.00549036 -0.00102018]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "[7, 13, 13, 18, 18, 18, 22, 22, 22, 22, 25, 25, 25, 25, 25, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 48, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cdf30beabd02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbTotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m#print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mISC_IBI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mISC_IBI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremoveNaNSubject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mISC_IBI\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mlast_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# Remove rows with NaNs\n",
    "def removeNaNSubject(matrix,subject):\n",
    "    new_mat = np.copy(matrix)\n",
    "    new_mat = np.delete(new_mat, (subject), axis=0)\n",
    "    new_mat = np.delete(new_mat, (subject), axis=1)\n",
    "    \n",
    "    '''\n",
    "    with open(os.path.join('school_EDA_truncated.csv'), 'w') as File:\n",
    "        writer = csv.writer(File,delimiter =';')\n",
    "        writer.writerows(matrix)\n",
    "    '''\n",
    "    \n",
    "    return new_mat\n",
    "# Remove outlier in vector if we find one\n",
    "def removeSubjectsVector(vector,subjects):\n",
    "    new_vect = np.copy(vector)\n",
    "    for subj in subjects:\n",
    "        new_vect = np.delete(new_vect, (subj), axis=0)\n",
    "    \n",
    "    return new_vect\n",
    "\n",
    "last_i = 0\n",
    "i = 0\n",
    "subjectsRemoved_EDA = []\n",
    "nbTotal = len(ISC_EDA)\n",
    "while (last_i < nbTotal and i < nbTotal - 1):\n",
    "    #print(nbTotal)\n",
    "    for i in range(nbTotal):\n",
    "        #print(i)\n",
    "        if ISC_EDA[0,i] == 0.:\n",
    "            ISC_EDA = removeNaNSubject(ISC_EDA,i)\n",
    "            last_i = i\n",
    "            nbTotal -= 1\n",
    "            #subjectsRemoved_EDA.append(i - nbTotal + 84)\n",
    "            subjectsRemoved_EDA.append(i)\n",
    "            break\n",
    "\n",
    "    #print(last_i)\n",
    "    \n",
    "print(ISC_EDA[:4,:4])\n",
    "print(subjectsRemoved_EDA)\n",
    "\n",
    "\n",
    "last_i = 0\n",
    "i = 0\n",
    "subjectsRemoved_IBI = []\n",
    "nbTotal = len(ISC_IBI)\n",
    "while (last_i < nbTotal and i < nbTotal - 1):\n",
    "    #print(nbTotal)\n",
    "    for i in range(nbTotal):\n",
    "        #print(i)\n",
    "        if ISC_IBI[0,i] == 0.:\n",
    "            ISC_IBI = removeNaNSubject(ISC_IBI,i)\n",
    "            last_i = i\n",
    "            nbTotal -= 1\n",
    "            #subjectsRemoved_IBI.append(i - nbTotal + 84)\n",
    "            subjectsRemoved_IBI.append(i)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeDistanceMatrix(study_matrix):\n",
    "    \n",
    "    # Normalise maximum value to 1\n",
    "    normed_matrix = np.copy(study_matrix)\n",
    "    normed_matrix = normed_matrix / np.max(abs(normed_matrix))\n",
    "    \n",
    "    # Convert into distance matrix\n",
    "    distance_matrix = np.sqrt((1-normed_matrix)) # Formula in Matlab and in Scikit to convert \n",
    "        \n",
    "    # Interval MDS normalization to spread values between 0 and 1\n",
    "    a = np.min(np.sort(distance_matrix,axis=0)[1,:])\n",
    "    distance_matrix = distance_matrix - a\n",
    "    distance_matrix = distance_matrix - np.diag(np.diag(distance_matrix))\n",
    "    distance_matrix = distance_matrix / np.max(distance_matrix)\n",
    "    \n",
    "    # To make sure output is perfectly symmetrical\n",
    "    return (distance_matrix+distance_matrix.T)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiview mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAllDistanceMatrix(ISC_EDA,ISC_IBI):\n",
    "    \n",
    "    # Make copy of 2 matrices (for each modality)\n",
    "    mat_EDA = np.copy(ISC_EDA)\n",
    "    mat_IBI = np.copy(ISC_IBI)\n",
    "    \n",
    "    # Compute the 2 distance matrices (according to each modality)\n",
    "    distance_matrix_EDA = computeDistanceMatrix(ISC_EDA)\n",
    "    distance_matrix_IBI = computeDistanceMatrix(ISC_IBI)\n",
    "  \n",
    "    # Remove direct correlation influence and compute correlation distance matrices\n",
    "    for i in range(len(mat_EDA)):\n",
    "        mat_EDA[i,i] = 0\n",
    "    for i in range(len(mat_IBI)):\n",
    "        mat_IBI[i,i] = 0\n",
    "    distance_matrix_corr_EDA = pairwise_distances(mat_EDA,metric='correlation')\n",
    "    distance_matrix_corr_IBI = pairwise_distances(mat_IBI,metric='correlation')\n",
    "\n",
    "    # Return distance matrices\n",
    "    return distance_matrix_EDA, distance_matrix_IBI, distance_matrix_corr_EDA, distance_matrix_corr_IBI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def computeAllDistanceMatrix(ISC_EDA,ISC_IBI):\n",
    "    \n",
    "    # Make copy of 2 matrices (for each modality)\n",
    "    mat_EDA = np.copy(ISC_EDA)\n",
    "    \n",
    "    # Compute the 2 distance matrices (according to each modality)\n",
    "    distance_matrix_EDA = computeDistanceMatrix(ISC_EDA)\n",
    "  \n",
    "    # Remove direct correlation influence and compute correlation distance matrices\n",
    "    for i in range(len(ISC_EDA)):\n",
    "        mat_EDA[i,i] = 0\n",
    "    distance_matrix_corr_EDA = pairwise_distances(mat_EDA,metric='correlation')\n",
    "\n",
    "    # Return distance matrices\n",
    "    return distance_matrix_EDA, distance_matrix_corr_EDA\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCoordinate(mat=['EDA','IBI','corrEDA','corrIBI'],added=False):\n",
    "\n",
    "    # Compute all distance matrices\n",
    "    distance_matrix_EDA, distance_matrix_IBI, distance_matrix_corr_EDA, distance_matrix_corr_IBI = computeAllDistanceMatrix(ISC_EDA,ISC_IBI)    \n",
    "    #distance_matrix_EDA, distance_matrix_corr_EDA = computeAllDistanceMatrix(ISC_EDA,ISC_IBI)    \n",
    "\n",
    "    # Choose which matrices to include into the multiview\n",
    "    multiviewMat = []\n",
    "    if ('EDA' in mat):\n",
    "        multiviewMat.append(distance_matrix_EDA)\n",
    "        distance_matrix = distance_matrix_EDA\n",
    "    if ('IBI' in mat):\n",
    "        multiviewMat.append(distance_matrix_IBI)\n",
    "        distance_matrix = distance_matrix_IBI\n",
    "    if ('corrEDA' in mat):\n",
    "        multiviewMat.append(distance_matrix_corr_EDA)\n",
    "    if ('corrIBI' in mat):\n",
    "        multiviewMat.append(distance_matrix_corr_IBI)\n",
    "        \n",
    "    # Compute mapping\n",
    "    embeddingDim = dim # to have a 2D map\n",
    "    \n",
    "    if len(mat)==1:\n",
    "        points = np.array(pcoa(distance_matrix, method='eigh', number_of_dimensions=embeddingDim).samples)\n",
    "        print(\"pcoa proportion explained : %s \" %np.sum(pcoa(distance_matrix, method='eigh', number_of_dimensions=embeddingDim).proportion_explained))\n",
    "    else:\n",
    "        points = mvmds(multiviewMat,len(mat)*[True],embeddingDim,added=added)\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def computeUMAPCoordinate(mat,sslLabel=None,n_neighbors=3):\n",
    "\n",
    "    if (mat==['EDA']):\n",
    "        study_matrix = ISC_EDA\n",
    "    if (mat==['IBI']):\n",
    "        study_matrix = ISC_IBI\n",
    "\n",
    "    print(dim)\n",
    "    print(type(dim))\n",
    "    fitter = umap.UMAP(n_components=int(dim),n_neighbors=n_neighbors,metric='correlation',min_dist=0.0,init='spectral',target_weight=0.5,n_epochs=5000).fit(study_matrix,sslLabel)\n",
    "    #points = preprocessing.scale(fitter.embedding_,axis=0)\n",
    "    points = (fitter.embedding_ - np.mean(fitter.embedding_,axis=0)) / np.std(fitter.embedding_,axis=0)\n",
    "    #print(np.std(points))\n",
    "    #print(np.mean(points))\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "def computeSCCoordinate(mat,gamma=1):\n",
    "    \n",
    "    distance_matrix_EDA, distance_matrix_IBI, distance_matrix_corr_EDA, distance_matrix_corr_IBI = computeAllDistanceMatrix(ISC_EDA,ISC_IBI)    \n",
    "    #distance_matrix_EDA, distance_matrix_corr_EDA = computeAllDistanceMatrix(ISC_EDA,ISC_IBI)    \n",
    "\n",
    "    if (mat==['EDA']):\n",
    "        distance_matrix = distance_matrix_EDA\n",
    "    if (mat==['IBI']):\n",
    "        distance_matrix = distance_matrix_IBI\n",
    "    \n",
    "    \n",
    "    clusteringDist = SpectralClustering(n_clusters=dim+1, n_init=10,affinity='precomputed')\n",
    "    affinity_matrix = np.exp(-gamma * distance_matrix ** 2)\n",
    "    clusteringDist.fit(affinity_matrix)\n",
    "    return clusteringDist.map_[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "def computeNoneCoordinate(mat):\n",
    "    \n",
    "    distance_matrix_EDA, distance_matrix_IBI, distance_matrix_corr_EDA, distance_matrix_corr_IBI = computeAllDistanceMatrix(ISC_EDA,ISC_IBI)    \n",
    "    #distance_matrix_EDA, distance_matrix_corr_EDA = computeAllDistanceMatrix(ISC_EDA,ISC_IBI)    \n",
    "\n",
    "    if (mat==['EDA']):\n",
    "        distance_matrix = distance_matrix_EDA\n",
    "    if (mat==['IBI']):\n",
    "        distance_matrix = distance_matrix_IBI\n",
    "    \n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results():\n",
    "\n",
    "    def __init__(self,mat,mapping,algo):\n",
    "        self.mat = mat\n",
    "        self.mapping = mapping\n",
    "        self.algo = algo\n",
    "        \n",
    "    def twoClustersMethodResult(self):\n",
    "        print(\"Blind results\\n\")\n",
    "        \n",
    "        # Cluster tendency\n",
    "        print(\"Hopkins test\")\n",
    "        self.hopkinsCoef()\n",
    "        print(\"%f +- %f\" %(self.hopkins[0],self.hopkins[1]))\n",
    "        \n",
    "        # Found clusters\n",
    "        print(\"Found clusters \")\n",
    "        print(self.label)\n",
    "        \n",
    "        # Clustering quality evaluation\n",
    "        print(\"Silhouette coefficient : %0.3f\" %self.silhouetteCoef())\n",
    "        print(\"DB index : %f \" %self.dbScore())\n",
    "        \n",
    "        # Comparing to ground truth (if known)\n",
    "        if (os.path.isfile(os.path.join('conditionSchool_EDA.csv')) and os.path.isfile(os.path.join('conditionSchool_IBI.csv'))):\n",
    "            global groundTruth\n",
    "            if (groundTruth):\n",
    "                print(\"\\n\\nComparing to ground truth\\n\")\n",
    "                print(\"Accuracy : %f \" %self.accuracy())\n",
    "                #print(\"Well participants : [%s]\" % \", \".join(map(str, self.wellClassified)))        \n",
    "                print(\"Misclassified participants : [%s]\" % \", \".join(map(str, self.misClassified)))        \n",
    "\n",
    "    def applyMethod(self,method):\n",
    "        \n",
    "        # Mapping\n",
    "        if (mapping == 'UMAP'):\n",
    "            points = computeUMAPCoordinate(self.mat)\n",
    "            #print(points)\n",
    "        elif (mapping == 'MDS'):\n",
    "            points = computeCoordinate(self.mat,added=False)\n",
    "        elif (mapping == 'MDS_scale'):\n",
    "            points = computeCoordinate(self.mat,added=True)\n",
    "        elif (mapping == 'SC'):\n",
    "            points = computeSCCoordinate(self.mat)\n",
    "        elif (mapping == 'None'): # distance matrix based clustering algorithm\n",
    "            print(\"dist meth\")\n",
    "            points = computeNoneCoordinate(self.mat)\n",
    "            if (algo == 'Spectral Clustering distance'):\n",
    "                points = np.exp(-method.gamma * points ** 2)\n",
    "        \n",
    "        # Clustering\n",
    "        # if (meth.distance_matrix):\n",
    "        if (algo == 'K-Medoids'):\n",
    "            meth = method.fit(pairwise_distances(points))\n",
    "        else:\n",
    "            meth = method.fit(points)\n",
    "\n",
    "        # Store found labels and points location\n",
    "        if hasattr(meth, 'labels_'):\n",
    "            label = meth.labels_\n",
    "        else:\n",
    "            label = meth.predict(points)\n",
    "            \n",
    "        self.label = label\n",
    "        self.best_points = points\n",
    "         \n",
    "    def showResultMap(self):\n",
    "        \n",
    "        # Set new figure\n",
    "        plt.figure()\n",
    "        ax = plt.axes([0,0,1.2,1.2])\n",
    "        ax.set_aspect(aspect='equal')\n",
    "        \n",
    "        # Annotate points\n",
    "        if mat == ['EDA']:\n",
    "            n = len(ISC_EDA)\n",
    "        elif mat == ['IBI']:\n",
    "            n = len(ISC_IBI)        \n",
    "        for i in range(n):\n",
    "            ax.annotate(i,(self.best_points[i,0],self.best_points[i,1]),xytext=(self.best_points[i,0]+(np.max(self.best_points[:,0])-np.min(self.best_points[:,0]))/50,self.best_points[i,1]))     \n",
    "    \n",
    "        # Show color according to trueDisplay bool\n",
    "        global trueDisplay\n",
    "        if (trueDisplay):\n",
    "            # Scatter points\n",
    "            for i in range(n_clusters):\n",
    "                ax.scatter(self.best_points[self.trueGroups[i],0],self.best_points[self.trueGroups[i],1],s=145,label=str(i))\n",
    "            \n",
    "            # Add legend\n",
    "            TP = mpatches.Patch(color='blue', label='NA')\n",
    "            TN = mpatches.Patch(color='red', label='SSA')\n",
    "            FP_FN = mpatches.Patch(color='black', label='misclassified')\n",
    "            #plt.legend(handles=[TP,TN,FP_FN])\n",
    "            plt.title(\"%s on [%s]\" % (self.algo, \", \".join(map(str, self.mat))))\n",
    "            #plt.axis('off')\n",
    "            #axes = plt.gca()\n",
    "            #axes.set_xlim([-0.4,0.4])\n",
    "            #axes.set_ylim([-0.4,0.7])\n",
    "            plt.savefig(os.path.join('figures','GT_%s.png' %self.mat),bbox_inches='tight')\n",
    "        else:\n",
    "            # Scatter points\n",
    "            for i in range(n_clusters):\n",
    "                ax.scatter(self.best_points[self.label == i,0],self.best_points[self.label == i,1],s=145,label=str(i))\n",
    "            \n",
    "            # Add legend\n",
    "            group0 = mpatches.Patch(color='darkgreen', label='First group')\n",
    "            group1 = mpatches.Patch(color='darkorange', label='Second group')\n",
    "            #plt.legend(handles=[group0,group1])       \n",
    "            plt.title(\"%s on [%s]\" % (self.algo, \", \".join(map(str, self.mat))))\n",
    "            #plt.axis('off')\n",
    "            plt.savefig(os.path.join('figures','clustering_%s.png' %self.mat),bbox_inches='tight')\n",
    "\n",
    "        \n",
    "    def dbScore(self):\n",
    "        # Compute DB-score (small means good clustering)\n",
    "        if len(np.unique(self.label))==1:\n",
    "            warnings.warn(\"Labels correspond to only 1 group\")\n",
    "            return -1\n",
    "        elif len(np.unique(self.label))==len(ISC_EDA):\n",
    "            warnings.warn(\"Each participant correspond to one label\")\n",
    "            return -1\n",
    "        elif len(np.unique(self.label))==len(ISC_IBI):\n",
    "            warnings.warn(\"Each participant correspond to one label\")\n",
    "            return -1\n",
    "        else:\n",
    "            return davies_bouldin_score(self.best_points,self.label)\n",
    "        \n",
    "    def hopkinsCoef(self):\n",
    "        # Average on different random data generated in Hopkins\n",
    "        H = []\n",
    "        if mat == ['EDA']:\n",
    "            n = len(ISC_EDA)\n",
    "        elif mat == ['IBI']:\n",
    "            n = len(ISC_IBI)\n",
    "        for p in range(100):\n",
    "            H.append(hopkins(self.best_points,n)) \n",
    "        self.hopkins = [1-np.mean(H),np.std(H)]\n",
    "        \n",
    "        # Raise a warning if Hopkins test <= 0.5\n",
    "        if (self.hopkins[0]<=0.5):\n",
    "            warnings.warn(\"Hopkins test <= 0.5 : data set does not have clustering tendency\")\n",
    "            \n",
    "    def silhouetteCoef(self):\n",
    "        # Compute Silhouette Coefficient based on distance matrix (the closer it is to 1, the better the clustering is)\n",
    "        if len(np.unique(self.label))==1:\n",
    "            warnings.warn(\"Labels correspond to only 1 group\")\n",
    "            return -1\n",
    "        elif len(np.unique(self.label))==len(ISC_EDA):\n",
    "            warnings.warn(\"Each participant correspond to one label\")\n",
    "            return -1\n",
    "        elif len(np.unique(self.label))==len(ISC_IBI):\n",
    "            warnings.warn(\"Each participant correspond to one label\")\n",
    "            return -1\n",
    "        else:\n",
    "            return silhouette_score(self.best_points, self.label, metric='euclidean')\n",
    "        \n",
    "    def accuracy(self):\n",
    "        # Read true labels from CSV file\n",
    "        condition = np.genfromtxt(os.path.join('conditionSchool_%s.csv' %mat[0]),delimiter=',')\n",
    "        condition = np.array(condition,dtype='int') # Convert into array\n",
    "        if mat == ['EDA']:\n",
    "            condition = removeSubjectsVector(condition,subjectsRemoved_EDA)\n",
    "        elif mat == ['IBI']:\n",
    "            condition = removeSubjectsVector(condition,subjectsRemoved_IBI)\n",
    "        self.trueGroups = []\n",
    "        for i in range(n_clusters):\n",
    "            self.trueGroups.append(np.where(condition == i)[0])\n",
    "        \n",
    "        # Find which participants are misclassified and compute accuracy\n",
    "        if mat == ['EDA']:\n",
    "            subjects = np.arange(len(ISC_EDA))\n",
    "        elif mat == ['IBI']:\n",
    "            subjects = np.arange(len(ISC_IBI))\n",
    "        self.wellClassified = subjects[self.label==condition]\n",
    "        self.misClassified = subjects[self.label!=condition]\n",
    "        '''if (len(self.misClassified) > len(self.wellClassified)):\n",
    "            self.wellClassified, self.misClassified = self.misClassified, self.wellClassified\n",
    "        \n",
    "        return len(self.wellClassified) / len(ISC_EDA)\n",
    "        '''\n",
    "        print(len(ISC_IBI))\n",
    "        print(condition)\n",
    "        print(self.label)\n",
    "        return accuracy(condition,self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which matrix or matrices to study\n",
    "mat = ['IBI']\n",
    "#mat = ['EDA','IBI']\n",
    "\n",
    "# Decide if compare to ground truth\n",
    "groundTruth = True\n",
    "\n",
    "# Display found clusters or true clusters with misclassified participants in black\n",
    "trueDisplay = True\n",
    "\n",
    "# Choose mapping method\n",
    "#mapping = 'UMAP'\n",
    "#mapping = 'MDS'\n",
    "#mapping = 'MDS_scale'\n",
    "mapping = 'SC'\n",
    "#mapping = 'None'\n",
    "\n",
    "# Choose clustering algorithm\n",
    "algo = 'K-Means'\n",
    "#algo = 'Spectral Clustering'\n",
    "#algo = 'Hierarchical Clustering'\n",
    "#algo = 'K-Medoids'\n",
    "\n",
    "#algo = 'Spectral Clustering distance'\n",
    "#algo = 'Hierarchical Clustering distance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute chosen clustering\n",
    "method_result = Results(mat=mat,mapping=mapping,algo=algo)\n",
    "n_clusters = 2\n",
    "dim = 2\n",
    "\n",
    "if (algo == 'K-Means'):\n",
    "    method = KMeans(n_clusters=n_clusters,n_init=100)\n",
    "elif (algo == 'Spectral Clustering'):\n",
    "    method = SpectralClustering(n_clusters=n_clusters,n_init=10,gamma=1)\n",
    "elif (algo == 'K-Medoids'):\n",
    "    method = KMedoids(n_clusters=n_clusters,tmax=1000)\n",
    "elif (algo == 'Hierarchical Clustering'):\n",
    "    method = AgglomerativeClustering(n_clusters=n_clusters,linkage=\"ward\")\n",
    "    \n",
    "elif (algo == 'Spectral Clustering distance'):\n",
    "    method = SpectralClustering(n_clusters=n_clusters,n_init=10,gamma=1,affinity='precomputed')\n",
    "elif (algo == 'Hierarchical Clustering distance'):\n",
    "    method = AgglomerativeClustering(n_clusters=n_clusters,linkage=\"single\",affinity='precomputed')\n",
    "#elif (algo == 'Hierarchical Clustering distance'): # ward doesnt work with precomputed matrix\n",
    "#    method = AgglomerativeClustering(n_clusters=n_clusters,linkage=\"ward\",affinity='precomputed')\n",
    "        \n",
    "method_result.applyMethod(method)\n",
    "\n",
    "# Show results\n",
    "method_result.twoClustersMethodResult()\n",
    "method_result.showResultMap()\n",
    "\n",
    "plt.figure()\n",
    "groundTruth = False\n",
    "trueDisplay = False\n",
    "method_result.showResultMap()\n",
    "\n",
    "from sklearn.metrics import homogeneity_score\n",
    "condition = np.genfromtxt(os.path.join('conditionSchool_%s.csv' %mat[0]),delimiter=',')\n",
    "condition = np.array(condition,dtype='int') # Convert into array\n",
    "if mat == ['EDA']:\n",
    "    condition = removeSubjectsVector(condition,subjectsRemoved_EDA)\n",
    "elif mat == ['IBI']:\n",
    "    condition = removeSubjectsVector(condition,subjectsRemoved_IBI)\n",
    "print(\"homogeneity\")\n",
    "print(homogeneity_score(condition,method_result.label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute chosen clustering\n",
    "method_result = Results(mat=mat,mapping=mapping,algo=algo)\n",
    "n_clusters = 17\n",
    "accDim = []\n",
    "allDim = np.arange(2,30)\n",
    "\n",
    "if (algo == 'K-Means'):\n",
    "    method = KMeans(n_clusters=n_clusters,n_init=100)\n",
    "elif (algo == 'Spectral Clustering'):\n",
    "    method = SpectralClustering(n_clusters=n_clusters,n_init=10,gamma=1)\n",
    "elif (algo == 'K-Medoids'):\n",
    "    method = KMedoids(n_clusters=n_clusters,tmax=1000)\n",
    "elif (algo == 'Hierarchical Clustering'):\n",
    "    method = AgglomerativeClustering(n_clusters=n_clusters,linkage=\"ward\")\n",
    "\n",
    "for dim in allDim:\n",
    "    method_result.applyMethod(method)\n",
    "    accDim.append(method_result.accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(allDim,accDim)\n",
    "plt.xlabel(\"number of dimensions\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "#\n",
    "\n",
    "#\n",
    "\n",
    "#\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test rendering with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    np.random.rand(100, 5),\n",
    "    columns=[\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    ")\n",
    "profile = ProfileReport(df, title='Pandas Profiling Report')\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(24)\n",
    "df = pd.DataFrame({'A': np.linspace(1, 10, 10)})\n",
    "df = pd.concat([df, pd.DataFrame(np.random.randn(10, 4), columns=list('BCDE'))],\n",
    "               axis=1)\n",
    "df.iloc[3, 3] = np.nan\n",
    "df.iloc[0, 2] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NaNs\n",
    "def removeNaNSubject(matrix,subject,period1,period2):\n",
    "    new_mat = np.copy(matrix)\n",
    "    new_mat = np.delete(new_mat[:,:,period1,period2], (subject), axis=0)\n",
    "    new_mat = np.delete(new_mat[:,:,period1,period2], (subject), axis=1)\n",
    "    \n",
    "    '''\n",
    "    with open(os.path.join('school_EDA_truncated.csv'), 'w') as File:\n",
    "        writer = csv.writer(File,delimiter =';')\n",
    "        writer.writerows(matrix)\n",
    "    '''\n",
    "    \n",
    "    return new_mat\n",
    "# Remove outlier in vector if we find one\n",
    "def removeSubjectsVector(vector,subjects):\n",
    "    new_vect = np.copy(vector)\n",
    "    for subj in subjects:\n",
    "        new_vect = np.delete(new_vect, (subj), axis=0)\n",
    "    \n",
    "    return new_vect\n",
    "'''\n",
    "last_i = 0\n",
    "i = 0\n",
    "subjectsRemoved_EDA = []\n",
    "nbTotal = ISC_EDA.shape[0]\n",
    "while (last_i < nbTotal and i < nbTotal - 1):\n",
    "    #print(nbTotal)\n",
    "    for i in range(nbTotal):\n",
    "        #print(i)\n",
    "        if ISC_EDA[0,i] == 0.:\n",
    "            ISC_EDA = removeNaNSubject(ISC_EDA,i)\n",
    "            last_i = i\n",
    "            nbTotal -= 1\n",
    "            #subjectsRemoved_EDA.append(i - nbTotal + 84)\n",
    "            subjectsRemoved_EDA.append(i)\n",
    "            break\n",
    "\n",
    "    #print(last_i)\n",
    "    \n",
    "print(ISC_EDA[:4,:4])\n",
    "print(subjectsRemoved_EDA)\n",
    "'''\n",
    "\n",
    "last_i = 0\n",
    "i = 0\n",
    "subjectsRemoved_IBI = []\n",
    "nbTotal = ISC_IBI.shape[0]\n",
    "print(ISC_IBI.shape)\n",
    "while (last_i < nbTotal and i < nbTotal - 1):\n",
    "    #print(nbTotal)\n",
    "    for i in range(nbTotal):\n",
    "        for period1 in range(nPeriod):\n",
    "            for period2 in range(nPeriod):\n",
    "                #print(i,period1,period2)\n",
    "                if ISC_IBI[0,i,period1,period2] == 0.:\n",
    "                    ISC_IBI = removeNaNSubject(ISC_IBI,i,period1,period2)\n",
    "                    last_i = i\n",
    "                    nbTotal -= 1\n",
    "                    #subjectsRemoved_IBI.append(i - nbTotal + 84)\n",
    "                    subjectsRemoved_IBI.append(i)\n",
    "                    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
